{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------------------------------------\n",
    "# Resnet50 model to build shared CNN layer\n",
    "# Original: .py file [Here is just a presentation]\n",
    "# Reference:\n",
    "#   [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "#   Adapted from code contributed by BigMoyan.\n",
    "# ------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Add, Dense, Activation, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, \\\n",
    "    AveragePooling2D, TimeDistributed\n",
    "from keras import backend as K\n",
    "from keras_frcnn.RoiPoolingConv import RoiPoolingConv\n",
    "from keras_frcnn.FixedBatchNormalization import FixedBatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####### From Reference #########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" basic blocks in resnet50. we selected these structures from original file \"\"\"\n",
    "\n",
    "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters    \n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def identity_block_td(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
    "    # identity block time distributed\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2a')(input_tensor)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), trainable=trainable, kernel_initializer='normal',padding='same'), name=conv_name_base + '2b')(x)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2c')(x)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
    "    x = Add()([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    x = Convolution2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
    "    shortcut = Convolution2D(nb_filter3, (1, 1), strides=strides, name=conv_name_base + '1', trainable=trainable)(input_tensor)\n",
    "    shortcut = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def conv_block_td(input_tensor, kernel_size, filters, stage, block, input_shape, strides=(2, 2), trainable=True):\n",
    "    # conv block time distributed\n",
    "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "\n",
    "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), input_shape=input_shape, name=conv_name_base + '2a')(input_tensor)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2b')(x)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), kernel_initializer='normal'), name=conv_name_base + '2c', trainable=trainable)(x)\n",
    "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
    "    shortcut = TimeDistributed(Convolution2D(nb_filter3, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '1')(input_tensor)\n",
    "    shortcut = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '1')(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### last part is over here #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shared CNN: Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nn_base(input_tensor=None, trainable=False):\n",
    "    ###### Determine proper input shape ######\n",
    "    # Difference between tensorflow and theano\n",
    "    \"\"\"Structure is a little bit different from baseline Resnet\"\"\"\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_shape = (3, None, None)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "\n",
    "\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    ###### Block 1 ######\n",
    "    x = ZeroPadding2D((3, 3))(img_input)\n",
    "    \n",
    "    ###### Block 2 ######\n",
    "    x = Convolution2D(64, (7, 7), strides=(2, 2), name='conv1', trainable = trainable)(x)\n",
    "    x = FixedBatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "    \n",
    "    ###### Block 3 ######\n",
    "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable = trainable)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', trainable = trainable)\n",
    "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', trainable = trainable)\n",
    "\n",
    "    ###### Block 4 ######\n",
    "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', trainable = trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', trainable = trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', trainable = trainable)\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', trainable = trainable)\n",
    "\n",
    "    ###### Block 5 ######\n",
    "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', trainable = trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', trainable = trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', trainable = trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', trainable = trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', trainable = trainable)\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', trainable = trainable)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Funtions to build faster rcnn model in the training process \n",
    "and rebuild corresponding faster rcnn model in the test process\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rpn(base_layers, num_anchors):\n",
    "    \"\"\"\n",
    "    Used for testing\n",
    "    inputs:\n",
    "        base_layers: feature map, output from shared CNN (raw feature extraction net)\n",
    "        num_anchors: in faster rcnn, equals to 3 x 3\n",
    "    output: \n",
    "        x_cls: 9-d, used to build cls_loss, cross entropy\n",
    "        x_regr: 4x9-d, used to build regr_loss, smooth L1\n",
    "    \"\"\"\n",
    "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
    "    x_cls = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
    "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
    "    return [x_cls, x_regr, base_layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
    "    \"\"\"\n",
    "    Used in training process and test process\n",
    "    Inputs:\n",
    "        base_layers: feature map, output from shared CNN (raw feature extraction net)\n",
    "        input_rois: roipooling layer\n",
    "        num_rois: number of rois\n",
    "    Outputs:\n",
    "        out_cls: inputs for cross entropy loss\n",
    "        out_regr: inputs for smooth L1 loss\n",
    "    \"\"\"\n",
    "    # backend checking\n",
    "    if K.backend() == 'tensorflow':\n",
    "        pooling_regions = 14\n",
    "        input_shape = (num_rois,14,14,1024)\n",
    "    elif K.backend() == 'theano':\n",
    "        pooling_regions = 7\n",
    "        input_shape = (num_rois,1024,7,7)\n",
    "\n",
    "    ##### Roipooling layer #####\n",
    "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
    "\n",
    "    ##### feature map generation layer #####\n",
    "    out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)\n",
    "    out = TimeDistributed(Flatten())(out)\n",
    "\n",
    "    ##### output layers #####\n",
    "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
    "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
    "    return [out_class, out_regr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_weight_path():\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        return 'resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
    "    else:\n",
    "        return 'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img_output_length(width, height):\n",
    "    \"\"\"\n",
    "    why: get_output_length like below\n",
    "    based on the resnet:  zero padding: +6\n",
    "                          strides = (2,2), padding='valid': \n",
    "                                then output_length = (input_length - filter_size + stride) // stride \n",
    "    \"\"\"\n",
    "    def get_output_length(input_length):\n",
    "        # reason: zero padding\n",
    "        input_length += 6\n",
    "        # reason: stride = (2,2), padding = 'valid'\n",
    "        filter_sizes = [7, 3, 1, 1]\n",
    "        stride = 2\n",
    "        for filter_size in filter_sizes:\n",
    "            input_length = (input_length - filter_size + stride) // stride\n",
    "        return input_length\n",
    "\n",
    "    return get_output_length(width), get_output_length(height) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
